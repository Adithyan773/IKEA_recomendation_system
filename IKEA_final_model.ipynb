{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LUC4cDmwtF80kMLRDqzBeVl5DlEfjCad",
      "authorship_tag": "ABX9TyP3jiC0ZNmd7yMyuCYWJURN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithyan773/IKEA_recomendation_system/blob/main/IKEA_final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu"
      ],
      "metadata": {
        "id": "IfMjnrwQkWRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnhqZcjzghfQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "from tensorflow.keras.layers import Dense, Input, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import faiss\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Custom DistilBERT embedding layer\n",
        "class DistilBertEmbeddingLayer(Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super(DistilBertEmbeddingLayer, self).__init__(**kwargs)\n",
        "        self.distilbert_model = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DistilBertEmbeddingLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# Load FAISS indices and metadata\n",
        "image_index = faiss.read_index('/content/image_embeddings_fixed.faiss')\n",
        "text_index = faiss.read_index('/content/text_embeddings_fixed.faiss')\n",
        "image_paths = np.load('/content/image_paths_fixed.npy')\n",
        "full_metadata = np.load('/content/full_metadata_fixed.npy', allow_pickle=True)\n",
        "\n",
        "# Define columns (consistent with text embedding code)\n",
        "all_columns = ['name', 'category', 'short_description', 'designer', 'depth', 'height', 'width', 'price', 'old_price', 'image_description']\n",
        "image_embeddings = np.array([image_index.reconstruct(i) for i in range(image_index.ntotal)])\n",
        "text_embeddings = np.array([text_index.reconstruct(i) for i in range(text_index.ntotal)])\n",
        "\n",
        "# Ensure consistent sample size\n",
        "n_samples = min(len(image_embeddings), len(text_embeddings), len(image_paths), len(full_metadata))\n",
        "image_embeddings = image_embeddings[:n_samples]\n",
        "text_embeddings = text_embeddings[:n_samples]\n",
        "image_paths = image_paths[:n_samples]\n",
        "full_metadata = full_metadata[:n_samples]\n",
        "\n",
        "# Create projection model\n",
        "def create_projection_model(input_dim=256, output_dim=256):\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    x = Dense(512, activation='relu')(input_layer)\n",
        "    x = Dense(output_dim, activation='relu')(x)\n",
        "    return Model(input_layer, x)\n",
        "\n",
        "text_projection = create_projection_model()\n",
        "image_projection = create_projection_model()\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "margin = 1.0\n",
        "\n",
        "# Train Siamese network with triplet loss\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    epoch_losses = []\n",
        "    permutation = np.random.permutation(n_samples)\n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        batch_indices = permutation[start:end]\n",
        "\n",
        "        text_batch = text_embeddings[batch_indices]\n",
        "        image_batch = image_embeddings[batch_indices]\n",
        "        neg_indices = np.random.choice(n_samples, len(batch_indices))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            text_proj = text_projection(text_batch)\n",
        "            image_proj = image_projection(image_batch)\n",
        "\n",
        "            neg_image_batch = image_embeddings[neg_indices]\n",
        "            neg_text_batch = text_embeddings[neg_indices]\n",
        "            neg_image_proj = image_projection(neg_image_batch)\n",
        "            neg_text_proj = text_projection(neg_text_batch)\n",
        "\n",
        "            pos_dist_text = tf.norm(text_proj - image_proj, axis=-1)\n",
        "            neg_dist_text = tf.norm(text_proj - neg_image_proj, axis=-1)\n",
        "            loss_text = tf.reduce_mean(tf.maximum(pos_dist_text - neg_dist_text + margin, 0.0))\n",
        "\n",
        "            pos_dist_image = tf.norm(image_proj - text_proj, axis=-1)\n",
        "            neg_dist_image = tf.norm(image_proj - neg_text_proj, axis=-1)\n",
        "            loss_image = tf.reduce_mean(tf.maximum(pos_dist_image - neg_dist_image + margin, 0.0))\n",
        "\n",
        "            loss = loss_text + loss_image\n",
        "            epoch_losses.append(loss.numpy())\n",
        "\n",
        "        grads = tape.gradient(loss, text_projection.trainable_weights + image_projection.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, text_projection.trainable_weights + image_projection.trainable_weights))\n",
        "\n",
        "    avg_epoch_loss = np.mean(epoch_losses)\n",
        "    print(f\"Epoch {epoch+1}  Loss: {avg_epoch_loss:.4f}\")\n",
        "\n",
        "# Project text embeddings\n",
        "projected_text_embeddings = text_projection.predict(text_embeddings, batch_size=32)\n",
        "projected_text_embeddings = projected_text_embeddings / np.linalg.norm(projected_text_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Create new FAISS index for projected text embeddings\n",
        "d = 256\n",
        "new_text_index = faiss.IndexFlatIP(d)\n",
        "new_text_index.add(projected_text_embeddings)\n",
        "\n",
        "# Load query model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('/content/drive/MyDrive/distilbert_v3')\n",
        "distilbert_base = TFDistilBertModel.from_pretrained('/content/drive/MyDrive/distilbert_v3', from_pt=True)\n",
        "query_input_ids = Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
        "query_attention_mask = Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
        "distilbert_layer = DistilBertEmbeddingLayer(distilbert_base)([query_input_ids, query_attention_mask])\n",
        "query_embedding = Dense(256, activation='relu', name='text_embedding')(distilbert_layer)\n",
        "query_model = Model([query_input_ids, query_attention_mask], query_embedding)\n",
        "query_model.load_weights('/content/text_model_weights_fixed.weights.h5')\n",
        "\n",
        "# Function to get projected query embedding\n",
        "def get_projected_query_embedding(query):\n",
        "    # Optional: Align with text embedding code by repeating query three times\n",
        "    enhanced_query = query + ' ' + query + ' ' + query\n",
        "    inputs = tokenizer(enhanced_query, return_tensors='tf', padding=True, truncation=True, max_length=128)\n",
        "    initial_embedding = query_model.predict([inputs['input_ids'], inputs['attention_mask']], verbose=0)\n",
        "    projected_embedding = text_projection.predict(initial_embedding, verbose=0)\n",
        "    projected_embedding = projected_embedding / np.linalg.norm(projected_embedding, axis=1, keepdims=True)\n",
        "    return projected_embedding[0]\n",
        "\n",
        "# Function to get top-k products (simplified, no material filtering)\n",
        "def get_top_k_products(query, k=5):\n",
        "    query_embedding = get_projected_query_embedding(query).reshape(1, -1)\n",
        "    similarities, indices = new_text_index.search(query_embedding, k)\n",
        "    top_k_indices = indices[0]\n",
        "    top_k_similarities = similarities[0]\n",
        "    top_k_images = [image_paths[idx] for idx in top_k_indices]\n",
        "    top_k_metadata = [dict(zip(all_columns, full_metadata[idx])) for idx in top_k_indices]\n",
        "    return top_k_similarities, top_k_images, top_k_metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the query\n",
        "query = \"small chair\"\n",
        "top_k_similarities, top_k_images, top_k_metadata = get_top_k_products(query, k=5)\n",
        "\n",
        "print(f\"Matches for query: '{query}':\")\n",
        "for i, (sim, img_path, meta) in enumerate(zip(top_k_similarities, top_k_images, top_k_metadata), 1):\n",
        "    print(f\"{i}. Similarity: {sim:.4f}\")\n",
        "    print(f\"   Image Path: {img_path}\")\n",
        "    try:\n",
        "        display(Image(filename=img_path, width=200, height=200))\n",
        "    except Exception as e:\n",
        "        print(f\"   [Error displaying image: {e}]\")\n",
        "    for col, value in meta.items():\n",
        "        print(f\"   {col.capitalize()}: {value}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "tpf_WHhOAPer"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}