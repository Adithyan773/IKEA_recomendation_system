{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-09ZAhQihquxQsHg1-9UQxjfI1u_hxgg",
      "authorship_tag": "ABX9TyNTncYV/uvBR2rHKzKorBZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithyan773/IKEA_recomendation_system/blob/main/IKEA_Text_Embedings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu"
      ],
      "metadata": {
        "id": "fJUK1serdGsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcFeD02MdO6o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "import faiss\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_csv('/content/ikea_data_img_fixed.csv')\n",
        "\n",
        "# Define image directory\n",
        "image_dir = '/content/drive/MyDrive/images/images'\n",
        "\n",
        "# Define columns\n",
        "text_columns = ['name', 'category', 'short_description', 'designer']\n",
        "numeric_columns = ['depth', 'height', 'width', 'price', 'old_price']\n",
        "all_columns = text_columns + numeric_columns\n",
        "\n",
        "# Emphasize image_description by repeating it three times\n",
        "df['combined_text'] = (df['image_description'] + ' ' + df['image_description'] + ' ' +\n",
        "                       df['image_description'] + ' ' + df['name'] + ' ' + df['category'] + ' ' +\n",
        "                       df['short_description'])\n",
        "\n",
        "# Load fine-tuned DistilBERT model and tokenizer\n",
        "model_path = '/content/drive/MyDrive/distilbert_v3'\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
        "distilbert_base = TFDistilBertModel.from_pretrained(model_path, from_pt=True)\n",
        "\n",
        "# Custom DistilBERT embedding layer\n",
        "class DistilBertEmbeddingLayer(Layer):\n",
        "    def __init__(self, distilbert_model, **kwargs):\n",
        "        super(DistilBertEmbeddingLayer, self).__init__(**kwargs)\n",
        "        self.distilbert_model = distilbert_model\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        outputs = self.distilbert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DistilBertEmbeddingLayer, self).get_config()\n",
        "        return config\n",
        "\n",
        "# Build text embedding model\n",
        "text_input_ids = Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
        "text_attention_mask = Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
        "bert_layer = DistilBertEmbeddingLayer(distilbert_base)([text_input_ids, text_attention_mask])\n",
        "text_embedding = Dense(256, activation='relu', name='text_embedding')(bert_layer)\n",
        "text_model = Model(inputs=[text_input_ids, text_attention_mask], outputs=text_embedding)\n",
        "\n",
        "# Tokenize the combined text\n",
        "inputs = tokenizer(df['combined_text'].tolist(), return_tensors='tf', padding=True, truncation=True, max_length=128)\n",
        "\n",
        "# Generate text embeddings\n",
        "combined_embeddings = text_model.predict([inputs['input_ids'], inputs['attention_mask']])\n",
        "\n",
        "# Normalize embeddings for cosine similarity\n",
        "combined_embeddings = combined_embeddings / np.linalg.norm(combined_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Create and populate FAISS index\n",
        "d = 256  # Embedding dimension\n",
        "text_index = faiss.IndexFlatIP(d)\n",
        "text_index.add(combined_embeddings)\n",
        "\n",
        "# Save FAISS index and metadata\n",
        "faiss.write_index(text_index, '/content/text_embeddings_fixed.faiss')\n",
        "metadata = df[all_columns + ['image_description']].to_numpy()  # Include image_description\n",
        "np.save('/content/full_metadata_fixed.npy', metadata)\n",
        "\n",
        "# Save model weights\n",
        "filepath = '/content/text_model_weights_fixed.weights.h5'\n",
        "text_model.save_weights(filepath)\n",
        "print(f\"Weights saved to: {filepath}\")\n",
        "\n",
        "print(f\"Number of texts indexed: {text_index.ntotal}\")\n",
        "print(f\"Metadata saved with shape: {metadata.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8NHTWdA9h01a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}